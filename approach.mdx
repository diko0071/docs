---
title: 'Процесс генерации ответа'
---
Последнее время можно все чаще видеть продукты, которые создаются на базе LLM, которые решают какую-то доменную проблему (внутренний помощник, клиентская поддержка и так далее). И все это происходит потому что реализовать подобные продукты — не так сложно. Все что вам нужно — доступ к OpenAI API, документы и пару функций на Python, чтобы получить продукт, который на первый взгляд работает как магия.

Но чем больше вы будете работать с этим, тем больше у вас будет «маленьких» проблем, которые, по сути, делают ваше решение нежизнеспособным продуктом, от которого можно получить пользу и сэкономить деньги на людях.

## Почему обычный ChatGPT + документы не очень хорошо работает? 
Не будем сильно вдаваться во все проблемы, озвучим лишь несколько самых важных из них.

### Галлюцинации. 
Это когда модель фантазирует. То есть говорит о том, чего на самом деле нет. И это просто невероятно большая проблема, особоенно, если мы говорим про работу с другим бизнесом. То есть продукт, который выдумывает факты, искажает их — несет огромные репутационные риски для бизнеса. Если бот что-то скажет запрещенное или не правду — это может вылиться в огромный скандал, потерю лояльности клиентов и огромные штрафы. 

Полностью галлюцинации избежать не получится. Едиственный способ как можно работать с ними — идентифицировать и минимизировать их влияние. 

### Стоимость. 
Если мы говорим про использования продвинутых моделей от OpenAI и Anthropic, которые сейчас используются в 99% всех возникших проектах — это дорого. Весь рынок чат-ботов в России привык к тому, что стоимость за сообщение не более, чем 2 рубля. Когда вы начинаете считать экономику с GPT-4 или Claude-2 — невольно можно прийти ужас, осознав, что ваше решение будет стоить 4+ рубля за сообщение. 

А если использовать менее эффективные модели (GPT-3.5-turbo, Claude-1), то тут уже начинаются вопросы, как у галлюцинациям, так и качеству. 

### Не соблюдение правил. 
Для любой компании очень важно, чтобы правила, которые они закладывают в систему — соблюдались. Тон разговора, информация о продукте, уточнение информации — и многое другое, что необходимо делать при каждой коммуникации с чат-ботом. 

Продукты с LLM могут делать это, но делаеют это не детерминированно (не постоянно). Модель может просто пропустить и не сделать того, что является обязательным. И это тоже большое «узкое горлышко» для всех продуктов на базе LLM, которые хотят работать с бизнесом. 

## Подход BrainFeed
Наша уникальность заключется в том, что внутри мы разработали подход, который позволяет сильно минизировать все 3 проблемы, о которых было сказано выше. 

На картинке ниже, вы можете увидеть то, как выглядит нах подход от момента вопроса пользователя, до получения ответа от модели. 

<Frame>
  <img src="/images/Group 1000004454.png" />
</Frame>

На каждом из 3-х уровней происходит обработка вашего вопроса и информации, которую вы загрузили. 

### Уровень 0. 
Нулевой уровень отвечает за то, чтобы система:

1. Получила правильный вопрос, учитывая вашу компанию, глоссарий, прошлые ответы и вопросы, которые вы задавали в систему. 

2. Правильно определили намерение вопроса, чтобы понять: а не спрашивали ли вы об этом раньше? И если да, то какой ответ вам понравился в прошлый раз, а какой ответ вам не понравился. 

То есть 0-ой уровень позволяет нам понять что именно вы хотите узнать, исходя из той информации, которая уже есть у модели о вашей компании. 

Чем лучше вопрос, тем лучше контекст, и тем лучше финальный ответ. 

### Уровень 1. 
На этом уровне происходит генерация ответа на ваш вопрос. В этом шаге самое важное то, какую информацию мы подаем модели, и каким образом мы это делаем. Чем чище, понятнее и релеватнее будет информация, тем проще для модели отдать качественный ответ. 

И это достатчно не простая задача, чтобы понять какой конретно контекст нужно дать модели, чтобы она ответила качественно. Для этого мы максимально расширяем пространство для поиска с высоким коэфицентом маржинальности, а далее начинаем сужать, чтобы найти исключительно релеватные сущности к вопросу пользователя. 

### Уровень 2.
Важнейший слой системы, на котором происходит несколько важны вещей: 

1. Проверка того, что модель не придумали ничего от себя и оперирует только информацией из контекста. 

2. Применение всех правил, которые пользователь указал. 

3. Работа с маленькими моделями, сохраняя высокий уровень качества и оставляя уровень затрат приемлимым.  

То есть как уже было написано выше — применение правил и оперирование только реальной информацией — ключевые критерии оценки продуктов бизнесом. Это безусловные вещи, которые бизнес ОЖИДАЕТ, чтобы это было.

## Выводы. 
Таким образом, уникальность подхода BrainFeed не в том, ЧТО мы используем — а КАК мы это используем. 

Благодаря нашему подходу мы можем быть уверены в том, что наша компания предоставляет качественный продукт на рынок, которые помогает бизнесу оптимизировать расходы на техническую поддержку, и время обучения новых сотрудников. 